# ğŸ§  Chat RAG con LangChain, LangGraph y Streamlit

Este proyecto implementa un sistema RAG (Retrieval-Augmented Generation) que permite al usuario subir documentos PDF y hacer preguntas sobre su contenido en lenguaje natural. Utiliza modelos LLM locales vÃ­a [Ollama](https://ollama.com), embeddings personalizados, y una arquitectura basada en `LangGraph`.

---

## ğŸš€ Â¿QuÃ© hace este proyecto?

- Permite subir un PDF y transformarlo en fragmentos indexados.
- Genera embeddings con `nomic-embed-text`.
- Responde preguntas usando un modelo local (como `llama3.2:3b`).
- Usa recuperaciÃ³n de contexto relevante del PDF.
- Usa Streamlit como interfaz conversacional.

---

## ğŸ› ï¸ Requisitos

- Python 3.10+
- Ollama instalado y corriendo 
- Modelos descargados:
  ```bash
  ollama pull llama3.2:3b
  ollama pull nomic-embed-text


  USO:
  instala dependencias
  uv add requirements.txt

  ejecuta la app con
  uv run uv streamlit rag7.py





Ejemplos de consultas y respuestas esperadas

 `Â¿QuÃ© es SellMoreTrips.IA?`                
 SellMoreTrips.IA es una plataforma impulsada por IA que ayuda a agentes de viaje a automatizar sus ventas. 
| `Â¿SellMoreTrips reemplaza a los agentes?` |
 No, es una herramienta de apoyo que los potencia, no los sustituye.    
`Â¿QuÃ© beneficios ofrece SellMoreTrips?`   
AutomatizaciÃ³n, cotizaciones instantÃ¡neas, atenciÃ³n 24/7 y personalizaciÃ³n de recomendaciones.             
 `Â¿CuÃ¡ndo muriÃ³ Albert Einstein?`
 No tengo informaciÃ³n sobre eso en este documento.                                                          


